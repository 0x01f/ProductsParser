# Парсер товаров -> Excel

Программа собирает данные о товарах по ссылке на страницу товара или на раздел каталога и сохраняет результат в Excel.

Собираемые поля:

- Название
- Цена
- Ссылка на товар
- Ссылка на изображение
- Описание (опционально)

Поддерживаются источники данных на странице: JSON-LD (schema.org/Product), OpenGraph и эвристики по DOM.

## Установка

1. Python 3.10+
2. Установить зависимости:

```bash
pip install -r requirements.txt
```

## Использование

Быстрый старт (выгрузка в текущую папку в `products.xlsx`):

```bash
python -m scraper "https://example.com/catalog"
```

Явно указать файл и шаблон:

```bash
python -m scraper "https://books.toscrape.com/" \
  --out "/path/to/output.xlsx" \
  --template "/path/to/template.xlsx" \
  --limit 100 --delay 0.3
```

Параметры:

- `url`: ссылка на сайт или раздел каталога
- `--out`: путь для сохранения Excel (по умолчанию `products.xlsx`)
- `--template`: путь к Excel-шаблону (необязательно)
- `--limit`: максимальное число товаров
- `--delay`: задержка между запросами (сек)
- `--user-agent`: переопределить User-Agent
- `--retries`: количество повторов при ошибках HTTP

## Шаблон Excel

Если указан путь к шаблону, данные будут записаны в первый лист шаблона. Если лист пустой, в первую строку будут записаны заголовки: `Название`, `Цена`, `Ссылка`, `Ссылка на изображение`, `Описание`.

## Заметки

- Соблюдайте robots.txt и правила сайта. Используйте умеренные значения `--delay` и `--limit`.
- На некоторых сайтах данные цен могут быть динамическими (JS). В таких случаях поможет JSON-LD или эвристики, но 100% извлечение не гарантируется.

